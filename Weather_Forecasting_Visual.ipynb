{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "intro",
      "metadata": {},
      "source": [
        "# Cohesive Weather Forecasting & Satellite Analysis Framework\n",
        "\n",
        "This notebook implements a comprehensive framework for processing satellite imagery for various weather forecasting tasks. It includes:\n",
        "\n",
        "1.  **Unified Configuration**: Centralized management of hyperparameters and paths.\n",
        "2.  **Data Pipeline**: Robust loading for the existing GIBS dataset (used for TMAX prediction).\n",
        "3.  **Model Zoo**: Implementation of 6 specific deep learning architectures from academic literature:\n",
        "    *   **GIBSForecaster**: The existing CNN+GRU model for TMAX prediction.\n",
        "    *   **CloudCoverNowcaster**: CNN for cloud cover segmentation (Berthomier et al., 2020).\n",
        "    *   **SIANet**: 3D-CNN for spatiotemporal rainfall prediction (Seo et al., 2022).\n",
        "    *   **Pix2PixLST**: cGAN for Land Surface Temperature & Emissivity (Garg et al., 2023).\n",
        "    *   **MicrowaveLSTNet**: CNN for LST from microwave data (Wang et al., 2020).\n",
        "    *   **ConvectionCNN**: CNN for intense convection detection (Cintineo et al., 2020).\n",
        "4.  **Training & Verification**: A unified training loop for the active task and verification steps for all model architectures."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "imports",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "import random\n",
        "from datetime import datetime, timedelta\n",
        "from pathlib import Path\n",
        "from collections import defaultdict\n",
        "import math\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image, UnidentifiedImageError\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as T\n",
        "\n",
        "# Ensure reproducibility\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "set_seed(42)\n",
        "\n",
        "print(f\"PyTorch: {torch.__version__}\")\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else (\"mps\" if torch.backends.mps.is_available() else \"cpu\"))\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "config",
      "metadata": {},
      "outputs": [],
      "source": [
        "class Config:\n",
        "    # Paths\n",
        "    DATA_ROOT = Path(\"/content/drive/MyDrive/DL/\")\n",
        "    GIBS_ROOT = DATA_ROOT / \"gibs\"\n",
        "    DAILIES_PATH = DATA_ROOT / \"dailies.csv\"\n",
        "    PROCESSED_DIR = DATA_ROOT / \"processed_tensors\"\n",
        "    \n",
        "    # Data Parameters\n",
        "    LOCATION = \"new_york_ny\"\n",
        "    HISTORY_DAYS = 30\n",
        "    IMAGE_SIZE = (128, 128)\n",
        "    TARGET_COLUMN = \"target_tmax_next_day\"\n",
        "    \n",
        "    # Training Hyperparameters\n",
        "    BATCH_SIZE = 32\n",
        "    LEARNING_RATE = 1e-4\n",
        "    NUM_EPOCHS = 10\n",
        "    \n",
        "    # Model Specific Defaults\n",
        "    # Number of channels will be inferred from data for the main task\n",
        "    # but we set defaults for others\n",
        "    DEFAULT_CHANNELS = 3\n",
        "    \n",
        "config = Config()\n",
        "config.PROCESSED_DIR.mkdir(exist_ok=True, parents=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "data_loading_markdown",
      "metadata": {},
      "source": [
        "## Data Loading (GIBS Dataset)\n",
        "This section handles the discovery and loading of the GIBS satellite imagery for the primary TMAX forecasting task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dataset_class",
      "metadata": {},
      "outputs": [],
      "source": [
        "class GIBSSequenceDataset(Dataset):\n",
        "    def __init__(self, end_dates, processed_dir, target_df, history_days=30, num_channels_expected=162):\n",
        "        self.end_dates = end_dates\n",
        "        self.processed_dir = processed_dir\n",
        "        self.target_df = target_df\n",
        "        self.history_days = history_days\n",
        "        self.num_channels_expected = num_channels_expected\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.end_dates)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        end_date = self.end_dates[idx]\n",
        "        # Calculate the 30-day window: [end_date - 29 days, ..., end_date]\n",
        "        window = [end_date - timedelta(days=i) for i in range(self.history_days - 1, -1, -1)]\n",
        "\n",
        "        frames = []\n",
        "        for d in window:\n",
        "            tensor_path = self.processed_dir / f\"{d}.pt\"\n",
        "            if tensor_path.exists():\n",
        "                # Load (C, H, W)\n",
        "                frames.append(torch.load(tensor_path, weights_only=True))\n",
        "            else:\n",
        "                # Fallback: create zeros\n",
        "                frames.append(torch.zeros((self.num_channels_expected, config.IMAGE_SIZE[0], config.IMAGE_SIZE[1])))\n",
        "\n",
        "        # Stack frames -> (History, Channels, H, W)\n",
        "        x = torch.stack(frames, dim=0)\n",
        "\n",
        "        # Get Target\n",
        "        try:\n",
        "            val = self.target_df.loc[pd.Timestamp(end_date), config.TARGET_COLUMN]\n",
        "            y = torch.tensor(val, dtype=torch.float32)\n",
        "        except KeyError:\n",
        "            y = torch.tensor(0.0, dtype=torch.float32)\n",
        "\n",
        "        return x, y\n",
        "\n",
        "def prepare_data(config):\n",
        "    # 1. Load Targets\n",
        "    if not config.DAILIES_PATH.exists():\n",
        "        print(\"Dailies CSV not found. Running in Demo Mode with dummy data.\")\n",
        "        return None, None, 162\n",
        "        \n",
        "    df = pd.read_csv(config.DAILIES_PATH)\n",
        "    df[\"DATE\"] = pd.to_datetime(df[\"DATE\"])\n",
        "    df = df.sort_values(\"DATE\").set_index(\"DATE\")\n",
        "    target = df[[\"TMAX\"]].rename(columns={\"TMAX\": config.TARGET_COLUMN})\n",
        "    target = target.shift(-1)  # Predict next day\n",
        "    target = target.dropna()\n",
        "    \n",
        "    # 2. Scan Processed Tensors\n",
        "    processed_files = sorted(list(config.PROCESSED_DIR.glob(\"*.pt\")))\n",
        "    if not processed_files:\n",
        "        print(\"No processed tensors found. Please run the preprocessing script first or ensure data is mounted.\")\n",
        "        return None, None, 162\n",
        "    \n",
        "    # Infer channels\n",
        "    sample = torch.load(processed_files[0], map_location=\"cpu\")\n",
        "    num_channels = sample.shape[0]\n",
        "    \n",
        "    processed_dates = set()\n",
        "    for pf in processed_files:\n",
        "        try:\n",
        "            processed_dates.add(datetime.strptime(pf.stem, \"%Y-%m-%d\").date())\n",
        "        except ValueError: pass\n",
        "        \n",
        "    # 3. Find Valid Sequences\n",
        "    valid_dates = []\n",
        "    target_dates = set(target.index.date)\n",
        "    sorted_dates = sorted(list(processed_dates))\n",
        "    available_set = set(sorted_dates)\n",
        "    \n",
        "    for d in sorted_dates:\n",
        "        if d not in target_dates:\n",
        "            continue\n",
        "        # Check contiguous window\n",
        "        is_valid = True\n",
        "        for i in range(config.HISTORY_DAYS):\n",
        "            if (d - timedelta(days=i)) not in available_set:\n",
        "                is_valid = False\n",
        "                break\n",
        "        if is_valid:\n",
        "            valid_dates.append(d)\n",
        "            \n",
        "    # 4. Split\n",
        "    split_idx = int(len(valid_dates) * 0.8)\n",
        "    train_dates = valid_dates[:split_idx]\n",
        "    test_dates = valid_dates[split_idx:]\n",
        "    \n",
        "    train_ds = GIBSSequenceDataset(train_dates, config.PROCESSED_DIR, target, config.HISTORY_DAYS, num_channels)\n",
        "    test_ds = GIBSSequenceDataset(test_dates, config.PROCESSED_DIR, target, config.HISTORY_DAYS, num_channels)\n",
        "    \n",
        "    return train_ds, test_ds, num_channels"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "model_zoo_markdown",
      "metadata": {},
      "source": [
        "# Model Zoo\n",
        "Here we implement the 6 requested models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "model_existing",
      "metadata": {},
      "outputs": [],
      "source": [
        "class DayEncoder(nn.Module):\n",
        "    \"\"\"Used by GIBSForecaster to encode one day's multi-channel image.\"\"\"\n",
        "    def __init__(self, in_channels, hidden_dim=128):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, 32, kernel_size=3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
        "            nn.Conv2d(32, 64, kernel_size=3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1), nn.ReLU(), nn.AdaptiveAvgPool2d((1,1)),\n",
        "        )\n",
        "        self.proj = nn.Linear(128, hidden_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, c, h, w = x.shape\n",
        "        z = self.net(x)\n",
        "        z = z.view(b, -1)\n",
        "        return self.proj(z)\n",
        "\n",
        "class GIBSForecaster(nn.Module):\n",
        "    \"\"\"\n",
        "    Current implementation for TMAX forecasting.\n",
        "    Input: (B, History, C, H, W)\n",
        "    Output: (B) -> Scalar Tmax\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels, history_days, hidden_dim=128, rnn_hidden=256):\n",
        "        super().__init__()\n",
        "        self.day_encoder = DayEncoder(in_channels, hidden_dim)\n",
        "        self.rnn = nn.GRU(hidden_dim, rnn_hidden, batch_first=True)\n",
        "        self.head = nn.Sequential(nn.Linear(rnn_hidden, 128), nn.ReLU(), nn.Linear(128, 1))\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, t, c, h, w = x.shape\n",
        "        x = x.view(b * t, c, h, w)\n",
        "        enc = self.day_encoder(x)  # (b*t, hidden)\n",
        "        enc = enc.view(b, t, -1)\n",
        "        out, _ = self.rnn(enc)\n",
        "        last = out[:, -1, :]\n",
        "        return self.head(last).squeeze(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "model_1_cloud_cover",
      "metadata": {},
      "outputs": [],
      "source": [
        "class CloudCoverNowcaster(nn.Module):\n",
        "    \"\"\"\n",
        "    Model 1: 'Cloud Cover Nowcasting' (Berthomier et al., 2020)\n",
        "    Objective: Predict next 6 timesteps of cloud cover.\n",
        "    Architecture: CNN (U-Net style or SegNet style).\n",
        "    Input: (B, 4, H, W) -> 4 consecutive grayscale images (or channels)\n",
        "    Output: (B, 6, H, W) -> Probabilities for next 6 timesteps\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels=4, out_timesteps=6):\n",
        "        super().__init__()\n",
        "        \n",
        "        # Encoder\n",
        "        self.enc1 = nn.Sequential(nn.Conv2d(in_channels, 64, 3, padding=1), nn.BatchNorm2d(64), nn.ReLU())\n",
        "        self.enc2 = nn.Sequential(nn.Conv2d(64, 128, 3, padding=1), nn.BatchNorm2d(128), nn.ReLU())\n",
        "        self.enc3 = nn.Sequential(nn.Conv2d(128, 256, 3, padding=1), nn.BatchNorm2d(256), nn.ReLU())\n",
        "        \n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        \n",
        "        # Bottleneck\n",
        "        self.bottleneck = nn.Sequential(nn.Conv2d(256, 512, 3, padding=1), nn.BatchNorm2d(512), nn.ReLU())\n",
        "        \n",
        "        # Decoder (Upsampling)\n",
        "        self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
        "        \n",
        "        self.dec3 = nn.Sequential(nn.Conv2d(512 + 256, 256, 3, padding=1), nn.BatchNorm2d(256), nn.ReLU())\n",
        "        self.dec2 = nn.Sequential(nn.Conv2d(256 + 128, 128, 3, padding=1), nn.BatchNorm2d(128), nn.ReLU())\n",
        "        self.dec1 = nn.Sequential(nn.Conv2d(128 + 64, 64, 3, padding=1), nn.BatchNorm2d(64), nn.ReLU())\n",
        "        \n",
        "        # Final prediction head\n",
        "        self.head = nn.Conv2d(64, out_timesteps, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: (B, 4, H, W)\n",
        "        e1 = self.enc1(x)\n",
        "        p1 = self.pool(e1)\n",
        "        \n",
        "        e2 = self.enc2(p1)\n",
        "        p2 = self.pool(e2)\n",
        "        \n",
        "        e3 = self.enc3(p2)\n",
        "        p3 = self.pool(e3)\n",
        "        \n",
        "        b = self.bottleneck(p3)\n",
        "        \n",
        "        # Decode with Skip Connections\n",
        "        d3 = self.dec3(torch.cat([self.up(b), e3], dim=1))\n",
        "        d2 = self.dec2(torch.cat([self.up(d3), e2], dim=1))\n",
        "        d1 = self.dec1(torch.cat([self.up(d2), e1], dim=1))\n",
        "        \n",
        "        # Output: (B, 6, H, W)\n",
        "        return torch.sigmoid(self.head(d1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "model_2_sianet",
      "metadata": {},
      "outputs": [],
      "source": [
        "class SIANet(nn.Module):\n",
        "    \"\"\"\n",
        "    Model 2: 'SIANet' (Seo et al., 2022)\n",
        "    Objective: Spatiotemporal rainfall prediction.\n",
        "    Architecture: 3D-CNN with Context Aggregation.\n",
        "    Input: (B, C, Depth/Time=4, H, W)\n",
        "    Output: (B, 1, Depth/Time=32, H, W)\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels=4, input_frames=4, output_frames=32):\n",
        "        super().__init__()\n",
        "        # 3D Convolution to process spatial+temporal\n",
        "        self.conv1 = nn.Conv3d(in_channels, 32, kernel_size=(3,3,3), padding=(1,1,1))\n",
        "        self.bn1 = nn.BatchNorm3d(32)\n",
        "        \n",
        "        # Context Aggregation (Dilated or Large Kernel)\n",
        "        self.context = nn.Conv3d(32, 64, kernel_size=(3,5,5), padding=(1,2,2))\n",
        "        self.bn2 = nn.BatchNorm3d(64)\n",
        "        \n",
        "        # Residual Block Sim\n",
        "        self.res_conv = nn.Conv3d(64, 64, kernel_size=3, padding=1)\n",
        "        \n",
        "        # Output generation: Upsample in time domain if needed \n",
        "        # (Simple implementation: Linear projection/Expansion)\n",
        "        self.temporal_expand = nn.ConvTranspose3d(64, 32, kernel_size=(output_frames//input_frames, 1, 1), stride=(output_frames//input_frames, 1, 1))\n",
        "        \n",
        "        self.out = nn.Conv3d(32, 1, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: (B, C, T, H, W)\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = F.relu(self.bn2(self.context(x)))\n",
        "        \n",
        "        # Residual connection\n",
        "        res = self.res_conv(x)\n",
        "        x = F.relu(x + res)\n",
        "        \n",
        "        # Expand time dimension (Input 4 -> Output 32)\n",
        "        x = self.temporal_expand(x)\n",
        "        \n",
        "        # Output: (B, 1, 32, H, W)\n",
        "        return self.out(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "model_3_pix2pix",
      "metadata": {},
      "outputs": [],
      "source": [
        "class Pix2PixGenerator(nn.Module):\n",
        "    \"\"\"\n",
        "    Model 3: Pix2Pix Generator (Garg et al., 2023)\n",
        "    Objective: Image-to-Image translation (Sat -> LST & Emissivity)\n",
        "    Input: (B, C, H, W)\n",
        "    Output: (B, 2, H, W) -> [LST, Emissivity]\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels=3, out_channels=2):\n",
        "        super().__init__()\n",
        "        # Simple U-Net Generator\n",
        "        self.down1 = nn.Conv2d(in_channels, 64, 4, 2, 1) # 64\n",
        "        self.down2 = nn.Conv2d(64, 128, 4, 2, 1) # 32\n",
        "        self.down3 = nn.Conv2d(128, 256, 4, 2, 1) # 16\n",
        "        \n",
        "        self.bottleneck = nn.Conv2d(256, 256, 4, 2, 1) # 8\n",
        "        \n",
        "        self.up1 = nn.ConvTranspose2d(256, 256, 4, 2, 1)\n",
        "        self.up2 = nn.ConvTranspose2d(256+256, 128, 4, 2, 1)\n",
        "        self.up3 = nn.ConvTranspose2d(128+128, 64, 4, 2, 1)\n",
        "        self.final = nn.ConvTranspose2d(64+64, out_channels, 4, 2, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        d1 = F.leaky_relu(self.down1(x), 0.2)\n",
        "        d2 = F.leaky_relu(self.down2(d1), 0.2)\n",
        "        d3 = F.leaky_relu(self.down3(d2), 0.2)\n",
        "        \n",
        "        b = F.relu(self.bottleneck(d3))\n",
        "        \n",
        "        u1 = F.relu(self.up1(b))\n",
        "        # Skip connections assumed concatenated\n",
        "        u1 = torch.cat([u1, d3], dim=1)\n",
        "        \n",
        "        u2 = F.relu(self.up2(u1))\n",
        "        u2 = torch.cat([u2, d2], dim=1)\n",
        "        \n",
        "        u3 = F.relu(self.up3(u2))\n",
        "        u3 = torch.cat([u3, d1], dim=1)\n",
        "        \n",
        "        return torch.tanh(self.final(u3))\n",
        "\n",
        "class Pix2PixDiscriminator(nn.Module):\n",
        "    \"\"\"\n",
        "    PatchGAN Discriminator\n",
        "    Input: (B, C_in + C_out, H, W)\n",
        "    Output: (B, 1, H/N, W/N)\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels=3+2):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, 64, 4, 2, 1), nn.LeakyReLU(0.2),\n",
        "            nn.Conv2d(64, 128, 4, 2, 1), nn.BatchNorm2d(128), nn.LeakyReLU(0.2),\n",
        "            nn.Conv2d(128, 1, 4, 1, 1) # Output patch predictions\n",
        "        )\n",
        "        \n",
        "    def forward(self, x):\n",
        "        return self.net(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "model_4_microwave",
      "metadata": {},
      "outputs": [],
      "source": [
        "class MicrowaveLSTNet(nn.Module):\n",
        "    \"\"\"\n",
        "    Model 4: Microwave LST (Wang et al., 2020)\n",
        "    Objective: Estimate LST from Passive Microwave data.\n",
        "    Architecture: CNN + FC.\n",
        "    Input: (B, C, H, W) where C = BTs + Ancillary\n",
        "    Output: (B, 1, H, W) or (B, 1) depending on resolution. Assuming map output.\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels=10):\n",
        "        super().__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, 32, 3, 1, 1), nn.ReLU(),\n",
        "            nn.Conv2d(32, 64, 3, 1, 1), nn.ReLU(),\n",
        "            nn.Conv2d(64, 32, 3, 1, 1), nn.ReLU(),\n",
        "        )\n",
        "        self.regressor = nn.Conv2d(32, 1, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        return self.regressor(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "model_5_convection",
      "metadata": {},
      "outputs": [],
      "source": [
        "class ConvectionCNN(nn.Module):\n",
        "    \"\"\"\n",
        "    Model 5: Intense Convection Detection (Cintineo et al., 2020)\n",
        "    Objective: Binary classification of intense convection.\n",
        "    Input: (B, C, H, W) -> C = Reflectance, Temp, GLM\n",
        "    Output: (B, 1) -> Probability\n",
        "    \"\"\"\n",
        "    def __init__(self, in_channels=3):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, 32, 3, 1), nn.ReLU(), nn.MaxPool2d(2),\n",
        "            nn.Conv2d(32, 64, 3, 1), nn.ReLU(), nn.MaxPool2d(2),\n",
        "            nn.Conv2d(64, 128, 3, 1), nn.ReLU(), nn.AdaptiveAvgPool2d((1,1)),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(128, 64), nn.ReLU(),\n",
        "            nn.Linear(64, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return torch.sigmoid(self.net(x))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "trainer_markdown",
      "metadata": {},
      "source": [
        "## Training Framework\n",
        "Unified trainer class for handling different model types."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "trainer",
      "metadata": {},
      "outputs": [],
      "source": [
        "class UnifiedTrainer:\n",
        "    def __init__(self, model, device, optimizer, criterion, task_type=\"regression\"):\n",
        "        self.model = model\n",
        "        self.device = device\n",
        "        self.optimizer = optimizer\n",
        "        self.criterion = criterion\n",
        "        self.task_type = task_type\n",
        "\n",
        "    def train_epoch(self, loader):\n",
        "        self.model.train()\n",
        "        total_loss = 0\n",
        "        for x, y in loader:\n",
        "            x = x.to(self.device)\n",
        "            y = y.to(self.device)\n",
        "            \n",
        "            self.optimizer.zero_grad()\n",
        "            \n",
        "            # Forward pass handling for different input types could go here\n",
        "            # For now we assume standard x -> y mapping\n",
        "            pred = self.model(x)\n",
        "            \n",
        "            loss = self.criterion(pred, y)\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "            \n",
        "            total_loss += loss.item()\n",
        "            \n",
        "        return total_loss / len(loader)\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def validate(self, loader):\n",
        "        self.model.eval()\n",
        "        total_loss = 0\n",
        "        for x, y in loader:\n",
        "            x = x.to(self.device)\n",
        "            y = y.to(self.device)\n",
        "            pred = self.model(x)\n",
        "            loss = self.criterion(pred, y)\n",
        "            total_loss += loss.item()\n",
        "        return total_loss / len(loader)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "verification_markdown",
      "metadata": {},
      "source": [
        "## Execution & Verification\n",
        "\n",
        "1. **Primary Task**: Train the `GIBSForecaster` on the available TMAX data.\n",
        "2. **Architecture Verification**: Instantiate all other models with dummy data to verify shape compatibility."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "run_tmax_train",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1. Run TMAX Training (Existing Task)\n",
        "print(\"=== Starting TMAX Forecast Training ===\")\n",
        "train_loader, test_loader, num_channels = prepare_data(config)\n",
        "\n",
        "if train_loader:\n",
        "    train_dl = DataLoader(train_loader, batch_size=config.BATCH_SIZE, shuffle=True)\n",
        "    test_dl = DataLoader(test_loader, batch_size=config.BATCH_SIZE)\n",
        "    \n",
        "    model_tmax = GIBSForecaster(in_channels=num_channels, history_days=config.HISTORY_DAYS).to(device)\n",
        "    optimizer = torch.optim.Adam(model_tmax.parameters(), lr=config.LEARNING_RATE)\n",
        "    criterion = nn.L1Loss() # MAE\n",
        "    \n",
        "    trainer = UnifiedTrainer(model_tmax, device, optimizer, criterion)\n",
        "    \n",
        "    for epoch in range(config.NUM_EPOCHS):\n",
        "        t_loss = trainer.train_epoch(train_dl)\n",
        "        v_loss = trainer.validate(test_dl)\n",
        "        print(f\"Epoch {epoch+1}/{config.NUM_EPOCHS} | Train MAE: {t_loss:.4f} | Val MAE: {v_loss:.4f}\")\n",
        "else:\n",
        "    print(\"Skipping training run (No data found).\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "verify_architectures",
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2. Verify Architectures (Dummy Data)\n",
        "print(\"\\n=== Verifying New Model Architectures ===\")\n",
        "H, W = 128, 128\n",
        "\n",
        "def verify_model(name, model, input_shape):\n",
        "    x = torch.randn(*input_shape).to(device)\n",
        "    try:\n",
        "        y = model(x)\n",
        "        print(f\"[PASS] {name}: Input {input_shape} -> Output {y.shape}\")\n",
        "    except Exception as e:\n",
        "        print(f\"[FAIL] {name}: {e}\")\n",
        "\n",
        "# Model 1: Cloud Cover\n",
        "m1 = CloudCoverNowcaster().to(device)\n",
        "verify_model(\"CloudCoverNowcaster\", m1, (2, 4, H, W))\n",
        "\n",
        "# Model 2: SIANet (3D)\n",
        "m2 = SIANet(in_channels=3, input_frames=4, output_frames=32).to(device)\n",
        "verify_model(\"SIANet\", m2, (2, 3, 4, H, W))\n",
        "\n",
        "# Model 3: Pix2Pix Generator\n",
        "m3_g = Pix2PixGenerator().to(device)\n",
        "verify_model(\"Pix2PixGenerator\", m3_g, (2, 3, H, W))\n",
        "\n",
        "# Model 3: Pix2Pix Discriminator\n",
        "m3_d = Pix2PixDiscriminator().to(device)\n",
        "# Input to disc is Cat(Real, Fake) -> Channels * 2 + Output channels\n",
        "verify_model(\"Pix2PixDiscriminator\", m3_d, (2, 5, H, W))\n",
        "\n",
        "# Model 4: Microwave LST\n",
        "m4 = MicrowaveLSTNet(in_channels=10).to(device)\n",
        "verify_model(\"MicrowaveLSTNet\", m4, (2, 10, H, W))\n",
        "\n",
        "# Model 5: Convection\n",
        "m5 = ConvectionCNN(in_channels=3).to(device)\n",
        "verify_model(\"ConvectionCNN\", m5, (2, 3, H, W))\n",
        "\n",
        "print(\"\\nAll architectures verified.\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
