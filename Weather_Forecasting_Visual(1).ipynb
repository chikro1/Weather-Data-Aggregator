{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "intro",
            "metadata": {},
            "source": [
                "# Cohesive Weather Forecasting & Satellite Analysis Framework\n",
                "\n",
                "This notebook implements a comprehensive framework for processing satellite imagery for various weather forecasting tasks. It includes:\n",
                "\n",
                "1.  **Unified Configuration**: Centralized management of hyperparameters and paths, including a **Smart Product Catalog**.\n",
                "2.  **Flexible Data Pipeline**: \n",
                "    *   **Smart Parsing**: Selects semantically relevant channels (e.g., just Visual + Lightning).\n",
                "    *   **All-Channel Mode**: Supports consumption of the full 162-channel tensor.\n",
                "3.  **Model Zoo**: Implementation of 6 specific deep learning architectures from academic literature.\n",
                "4.  **Robust Training**: Unified trainer with **Verbose Logging** and strict GPU utilization checks."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "colab_mount",
            "metadata": {},
            "outputs": [],
            "source": [
                "try:\n",
                "    from google.colab import drive\n",
                "    drive.mount('/content/drive')\n",
                "    print(\"Google Drive mounted successfully.\")\n",
                "except ImportError:\n",
                "    print(\"Not running in Google Colab, skipping Drive mount.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "gpu_setup",
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "import os\n",
                "import sys\n",
                "\n",
                "# === GPU/Performance Optimization ===\n",
                "REQUIRE_GPU = False  # Set to True to raise error if no GPU found\n",
                "\n",
                "if torch.cuda.is_available():\n",
                "    DEVICE = torch.device(\"cuda\")\n",
                "    # Optimizations for fixed-size inputs\n",
                "    torch.backends.cudnn.benchmark = True \n",
                "    torch.backends.cudnn.enabled = True\n",
                "elif torch.backends.mps.is_available():\n",
                "    DEVICE = torch.device(\"mps\")\n",
                "else:\n",
                "    DEVICE = torch.device(\"cpu\")\n",
                "\n",
                "print(f\"=== SYSTEM DIAGNOSTICS ===\")\n",
                "print(f\"Python Version: {sys.version.split()[0]}\")\n",
                "print(f\"PyTorch Version: {torch.__version__}\")\n",
                "print(f\"Selected Device: {DEVICE}\")\n",
                "\n",
                "if DEVICE.type == \"cuda\":\n",
                "    print(f\"CUDA Device Name: {torch.cuda.get_device_name(0)}\")\n",
                "    print(f\"CUDA Capability: {torch.cuda.get_device_capability(0)}\")\n",
                "    print(f\"Memory Allocated: {torch.cuda.memory_allocated(0) / 1024**3:.2f} GB\")\n",
                "    print(f\"Memory Cached: {torch.cuda.memory_reserved(0) / 1024**3:.2f} GB\")\n",
                "    torch.cuda.empty_cache()\n",
                "    print(\"Cache cleared.\")\n",
                "elif DEVICE.type == \"mps\":\n",
                "    print(\"Using Apple Metal Performance Shaders (MPS).\")\n",
                "else:\n",
                "    print(\"WARNING: Running on CPU. Training will be slow.\")\n",
                "\n",
                "if REQUIRE_GPU and DEVICE.type == \"cpu\":\n",
                "    raise RuntimeError(\"No GPU found! Check Runtime > Change runtime type in Colab.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "imports",
            "metadata": {},
            "outputs": [],
            "source": [
                "import glob\n",
                "import random\n",
                "from datetime import datetime, timedelta\n",
                "from pathlib import Path\n",
                "from collections import defaultdict\n",
                "import math\n",
                "import time\n",
                "\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "import torch.nn as nn\n",
                "import torch.nn.functional as F\n",
                "from torch.utils.data import Dataset, DataLoader\n",
                "\n",
                "# Ensure reproducibility\n",
                "def set_seed(seed=42):\n",
                "    random.seed(seed)\n",
                "    np.random.seed(seed)\n",
                "    torch.manual_seed(seed)\n",
                "    if torch.cuda.is_available():\n",
                "        torch.cuda.manual_seed_all(seed)\n",
                "\n",
                "set_seed(42)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "config",
            "metadata": {},
            "outputs": [],
            "source": [
                "class Config:\n",
                "    # Paths\n",
                "    if Path(\"/content/drive/MyDrive/DL/\").exists():\n",
                "        DATA_ROOT = Path(\"/content/drive/MyDrive/DL/\")\n",
                "    else:\n",
                "        DATA_ROOT = Path(\"./data\") \n",
                "        \n",
                "    DAILIES_PATH = DATA_ROOT / \"dailies.csv\"\n",
                "    PROCESSED_ROOT = DATA_ROOT / \"processed_tensors\"\n",
                "    \n",
                "    # Data Parameters\n",
                "    LOCATION = \"new_york_ny\"\n",
                "    HISTORY_DAYS = 30\n",
                "    IMAGE_SIZE = (128, 128)\n",
                "    TARGET_COLUMN = \"target_tmax_next_day\"\n",
                "    \n",
                "    # Training Hyperparameters\n",
                "    BATCH_SIZE = 32\n",
                "    LEARNING_RATE = 1e-4\n",
                "    NUM_EPOCHS = 10\n",
                "    \n",
                "    # --- SMART PRODUCT CATALOG ---\n",
                "    PRODUCT_CATALOG = [\n",
                "        \"AMSRU2_Sea_Ice_Brightness_Temp_6km_89H\",\n",
                "        \"AMSRU2_Sea_Ice_Brightness_Temp_6km_89V\",\n",
                "        \"AMSRU2_Sea_Ice_Concentration_12km\",\n",
                "        \"AMSUA_NOAA15_Brightness_Temp_Channel_1\",\n",
                "        \"AMSUA_NOAA15_Brightness_Temp_Channel_10\",\n",
                "        \"AMSUA_NOAA15_Brightness_Temp_Channel_12\",\n",
                "        \"AMSUA_NOAA15_Brightness_Temp_Channel_13\",\n",
                "        \"AMSUA_NOAA15_Brightness_Temp_Channel_15\",\n",
                "        \"AMSUA_NOAA15_Brightness_Temp_Channel_2\",\n",
                "        \"AMSUA_NOAA15_Brightness_Temp_Channel_3\",\n",
                "        \"AMSUA_NOAA15_Brightness_Temp_Channel_4\",\n",
                "        \"AMSUA_NOAA15_Brightness_Temp_Channel_5\",\n",
                "        \"AMSUA_NOAA15_Brightness_Temp_Channel_6\",\n",
                "        \"AMSUA_NOAA15_Brightness_Temp_Channel_7\",\n",
                "        \"AMSUA_NOAA15_Brightness_Temp_Channel_8\",\n",
                "        \"AMSUA_NOAA15_Brightness_Temp_Channel_9\",\n",
                "        \"GHRSST_L4_AVHRR-OI_Sea_Surface_Temperature\",\n",
                "        \"GHRSST_L4_MUR_Sea_Ice_Concentration\",\n",
                "        \"GOES-East_ABI_GeoColor\",\n",
                "        \"GOES-West_ABI_GeoColor\",\n",
                "        \"IMERG_Precipitation_Rate_30min\",\n",
                "        \"LIS_TRMM_Flash_Radiance\",\n",
                "        \"MERRA2_ISCCP_Cloud_Albedo_Monthly\",\n",
                "        \"MODIS_Aqua_Cloud_Optical_Thickness_16\",\n",
                "        \"MODIS_Aqua_Cloud_Top_Height_Day\",\n",
                "        \"MODIS_Aqua_Cloud_Top_Temp_Day\",\n",
                "        \"MODIS_Aqua_Cloud_Top_Temp_Night\",\n",
                "        \"MODIS_Aqua_CorrectedReflectance_Bands721\",\n",
                "        \"MODIS_Aqua_CorrectedReflectance_TrueColor\",\n",
                "        \"MODIS_Aqua_L2_Chlorophyll_A\",\n",
                "        \"MODIS_Aqua_L3_NDSI_Snow_Cover_Daily\",\n",
                "        \"MODIS_Aqua_SurfaceReflectance_Bands121\",\n",
                "        \"MODIS_Terra_Cloud_Optical_Thickness_16\",\n",
                "        \"MODIS_Terra_Cloud_Top_Height_Day\",\n",
                "        \"MODIS_Terra_Cloud_Top_Temp_Day\",\n",
                "        \"MODIS_Terra_Cloud_Top_Temp_Night\",\n",
                "        \"MODIS_Terra_CorrectedReflectance_Bands367\",\n",
                "        \"MODIS_Terra_CorrectedReflectance_Bands721\",\n",
                "        \"MODIS_Terra_CorrectedReflectance_TrueColor\",\n",
                "        \"MODIS_Terra_L2_Chlorophyll_A\",\n",
                "        \"MODIS_Terra_L3_NDSI_Snow_Cover_Daily\",\n",
                "        \"MODIS_Terra_SurfaceReflectance_Bands121\",\n",
                "        \"OSCAR_Sea_Surface_Currents_Meridional\",\n",
                "        \"OSCAR_Sea_Surface_Currents_Zonal\",\n",
                "        \"SSMI_DMSP_F11_Cloud_Liquid_Water_Over_Oceans_Ascending\",\n",
                "        \"SSMI_DMSP_F11_Cloud_Liquid_Water_Over_Oceans_Descending\",\n",
                "        \"TOPEX-Poseidon_JASON_Sea_Surface_Height_Anomalies_GDR_Cycles\",\n",
                "        \"TRMM_Brightness_Temp_Asc\",\n",
                "        \"TRMM_Brightness_Temp_Dsc\",\n",
                "        \"TRMM_Precipitation_Rate_Asc\",\n",
                "        \"TRMM_Precipitation_Rate_Dsc\",\n",
                "        \"VIIRS_NOAA20_CorrectedReflectance_TrueColor_Granule\",\n",
                "        \"VIIRS_SNPP_CorrectedReflectance_TrueColor_Granule\",\n",
                "        \"VIIRS_SNPP_L2_Chlorophyll_A\"\n",
                "    ]\n",
                "    \n",
                "    @staticmethod\n",
                "    def get_indices(product_name_substring):\n",
                "        for i, name in enumerate(Config.PRODUCT_CATALOG):\n",
                "            if product_name_substring in name:\n",
                "                return i * 3, i * 3 + 3\n",
                "        print(f\"WARNING: Product matching '{product_name_substring}' not found. Using indices 0-3.\")\n",
                "        return 0, 3\n",
                "        \n",
                "    @staticmethod\n",
                "    def select_channels(tensor, product_names):\n",
                "        chunks = []\n",
                "        for name in product_names:\n",
                "            start, end = Config.get_indices(name)\n",
                "            if start >= tensor.shape[0]:\n",
                "                chunks.append(torch.zeros((3, tensor.shape[1], tensor.shape[2])))\n",
                "            else:\n",
                "                chunks.append(tensor[start:end])\n",
                "        return torch.cat(chunks, dim=0)\n",
                "\n",
                "config = Config()\n",
                "if config.PROCESSED_ROOT.exists():\n",
                "    config.PROCESSED_ROOT.mkdir(parents=True, exist_ok=True)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "dataset_markdown",
            "metadata": {},
            "source": [
                "## Smart Data Loading with All-Channel Support\n",
                "\n",
                "Datasets now accept `use_all_channels=True/False`.\n",
                "*   `False`: Use semantic selection (e.g., 3 channels).\n",
                "*   `True`: Use 162 channels."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "dataset_classes",
            "metadata": {},
            "outputs": [],
            "source": [
                "class BaseSlicingDataset(Dataset):\n",
                "    def __init__(self, file_paths, use_all_channels=False):\n",
                "        self.files = sorted(file_paths)\n",
                "        self.use_all_channels = use_all_channels\n",
                "    def __len__(self):\n",
                "        return len(self.files)\n",
                "    def load_tensor(self, path):\n",
                "        return torch.load(path, weights_only=True)\n",
                "    def _get_input(self, data, semantic_selection_func):\n",
                "        if self.use_all_channels:\n",
                "            return data # All 162 channels\n",
                "        else:\n",
                "            return semantic_selection_func(data)\n",
                "    def __getitem__(self, idx):\n",
                "        raise NotImplementedError()\n",
                "\n",
                "# --- 1. Existing TMAX Forecasting Dataset ---\n",
                "class GIBSSequenceDataset(Dataset):\n",
                "    def __init__(self, end_dates, processed_dir, target_df, history_days=30, num_channels_expected=162):\n",
                "        self.end_dates = end_dates\n",
                "        self.processed_dir = processed_dir\n",
                "        self.target_df = target_df\n",
                "        self.history_days = history_days\n",
                "        self.num_channels_expected = num_channels_expected\n",
                "\n",
                "    def __len__(self):\n",
                "        return len(self.end_dates)\n",
                "\n",
                "    def __getitem__(self, idx):\n",
                "        end_date = self.end_dates[idx]\n",
                "        window = [end_date - timedelta(days=i) for i in range(self.history_days - 1, -1, -1)]\n",
                "        frames = []\n",
                "        for d in window:\n",
                "            tensor_path = self.processed_dir / f\"{d}.pt\"\n",
                "            if tensor_path.exists():\n",
                "                frames.append(torch.load(tensor_path, weights_only=True))\n",
                "            else:\n",
                "                frames.append(torch.zeros((self.num_channels_expected, config.IMAGE_SIZE[0], config.IMAGE_SIZE[1])))\n",
                "        x = torch.stack(frames, dim=0)\n",
                "        try:\n",
                "            val = self.target_df.loc[pd.Timestamp(end_date), config.TARGET_COLUMN]\n",
                "            y = torch.tensor(val, dtype=torch.float32)\n",
                "        except KeyError:\n",
                "            y = torch.tensor(0.0, dtype=torch.float32)\n",
                "        return x, y\n",
                "\n",
                "# --- 2. Model 1: Cloud Cover Dataset ---\n",
                "class CloudCoverDataset(BaseSlicingDataset):\n",
                "    def __getitem__(self, idx):\n",
                "        data = self.load_tensor(self.files[idx])\n",
                "        \n",
                "        def select_semantic(d):\n",
                "             x_sel = Config.select_channels(d, [\"GOES-East_ABI_GeoColor\"])\n",
                "             return torch.cat([x_sel, x_sel[:1]], dim=0) # Pad to 4\n",
                "\n",
                "        x = self._get_input(data, select_semantic)\n",
                "        y = torch.cat([x, x], dim=0)[:6] # Dummy target of size 6\n",
                "        if y.shape[0] < 6: y = torch.cat([y, y], dim=0)[:6] # Ensure size\n",
                "        return x, y\n",
                "\n",
                "# --- 3. Model 2: SIANet Dataset ---\n",
                "class SIANetDataset(Dataset):\n",
                "    def __init__(self, valid_dates, processed_dir, use_all_channels=False):\n",
                "        self.dates = sorted(valid_dates)\n",
                "        self.dir = processed_dir\n",
                "        self.use_all_channels = use_all_channels\n",
                "    \n",
                "    def __len__(self):\n",
                "        return len(self.dates)\n",
                "\n",
                "    def __getitem__(self, idx):\n",
                "        end_d = self.dates[idx]\n",
                "        window = [end_d - timedelta(days=i) for i in range(3, -1, -1)]\n",
                "        frames = []\n",
                "        for d in window:\n",
                "            p = self.dir / f\"{d}.pt\"\n",
                "            if p.exists():\n",
                "                d_tensor = torch.load(p, weights_only=True)\n",
                "                if self.use_all_channels:\n",
                "                    frames.append(d_tensor)\n",
                "                else:\n",
                "                    goes = Config.select_channels(d_tensor, [\"GOES-East_ABI_GeoColor\"])\n",
                "                    water = Config.select_channels(d_tensor, [\"SSMI_DMSP_F11_Cloud_Liquid_Water_Over_Oceans_Descending\"])\n",
                "                    frames.append(torch.cat([goes, water[:1]], dim=0))\n",
                "            else:\n",
                "                C = 162 if self.use_all_channels else 4\n",
                "                frames.append(torch.zeros((C, config.IMAGE_SIZE[0], config.IMAGE_SIZE[1])))\n",
                "        \n",
                "        x_seq = torch.stack(frames, dim=1) \n",
                "        y = torch.zeros((1, 32, x_seq.shape[-2], x_seq.shape[-1]))\n",
                "        return x_seq, y\n",
                "\n",
                "# --- 4. Model 3: Pix2Pix Dataset ---\n",
                "class Pix2PixDataset(BaseSlicingDataset):\n",
                "    def __getitem__(self, idx):\n",
                "        data = self.load_tensor(self.files[idx])\n",
                "        \n",
                "        def select_semantic(d):\n",
                "            return Config.select_channels(d, [\"GOES-East_ABI_GeoColor\"])\n",
                "\n",
                "        x = self._get_input(data, select_semantic)\n",
                "        # Target remains fixed (LST)\n",
                "        therm = Config.select_channels(data, [\"MODIS_Aqua_Cloud_Top_Temp_Day\", \"MODIS_Aqua_Cloud_Top_Temp_Night\"])\n",
                "        y = therm[:2]\n",
                "        return x, y\n",
                "\n",
                "# --- 5. Model 4: Microwave Dataset ---\n",
                "class MicrowaveDataset(BaseSlicingDataset):\n",
                "    def __getitem__(self, idx):\n",
                "        data = self.load_tensor(self.files[idx])\n",
                "        \n",
                "        def select_semantic(d):\n",
                "            inputs = [\n",
                "                \"AMSUA_NOAA15_Brightness_Temp_Channel_1\", \"AMSUA_NOAA15_Brightness_Temp_Channel_2\",\n",
                "                \"AMSUA_NOAA15_Brightness_Temp_Channel_3\", \"AMSUA_NOAA15_Brightness_Temp_Channel_4\"\n",
                "            ]\n",
                "            raw = Config.select_channels(d, inputs)\n",
                "            return raw[:10] if raw.shape[0] >= 10 else F.pad(raw, (0,0,0,0,0,10-raw.shape[0]))\n",
                "\n",
                "        x = self._get_input(data, select_semantic)\n",
                "        y = Config.select_channels(data, [\"TRMM_Brightness_Temp_Asc\"])[:1]\n",
                "        return x, y\n",
                "\n",
                "# --- 6. Model 5: Convection Dataset ---\n",
                "class ConvectionDataset(BaseSlicingDataset):\n",
                "    def __getitem__(self, idx):\n",
                "        data = self.load_tensor(self.files[idx])\n",
                "        \n",
                "        def select_semantic(d):\n",
                "            vis = Config.select_channels(d, [\"GOES-East_ABI_GeoColor\"])[:1]\n",
                "            ir = Config.select_channels(d, [\"MODIS_Aqua_Cloud_Top_Temp_Day\"])[:1]\n",
                "            ltg = Config.select_channels(d, [\"LIS_TRMM_Flash_Radiance\"])[:1]\n",
                "            return torch.cat([vis, ir, ltg], dim=0)\n",
                "\n",
                "        x = self._get_input(data, select_semantic)\n",
                "        y = torch.tensor([0.0])\n",
                "        return x, y"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "data_prep_and_discovery",
            "metadata": {},
            "outputs": [],
            "source": [
                "def discover_files(config):\n",
                "    \"\"\"Shared discovery of .pt files and dates.\"\"\"\n",
                "    if not config.PROCESSED_ROOT.exists():\n",
                "        return [], []\n",
                "        \n",
                "    files = sorted(list(config.PROCESSED_ROOT.glob(\"*.pt\")))\n",
                "    dates = []\n",
                "    for pf in files:\n",
                "        try:\n",
                "            dates.append(datetime.strptime(pf.stem, \"%Y-%m-%d\").date())\n",
                "        except ValueError:\n",
                "            pass\n",
                "    return files, dates\n",
                "\n",
                "def prepare_tmax_data(config): \n",
                "    files, dates = discover_files(config)\n",
                "    if not files:\n",
                "        print(\"No files found for TMAX training.\")\n",
                "        return None, None, 162\n",
                "    \n",
                "    # Load targets\n",
                "    if not config.DAILIES_PATH.exists():\n",
                "        return None, None, 162\n",
                "        \n",
                "    df = pd.read_csv(config.DAILIES_PATH)\n",
                "    df[\"DATE\"] = pd.to_datetime(df[\"DATE\"])\n",
                "    df = df.sort_values(\"DATE\").set_index(\"DATE\")\n",
                "    target = df[[\"TMAX\"]].rename(columns={\"TMAX\": config.TARGET_COLUMN})\n",
                "    target = target.shift(-1)\n",
                "    target = target.dropna()\n",
                "    \n",
                "    # Filter valid dates\n",
                "    valid_dates = []\n",
                "    target_dates = set(target.index.date)\n",
                "    for d in dates:\n",
                "        if d in target_dates:\n",
                "             valid_dates.append(d)\n",
                "    \n",
                "    # Check num channels\n",
                "    try:\n",
                "        sample = torch.load(files[0], map_location=\"cpu\")\n",
                "        num_channels = sample.shape[0]\n",
                "    except:\n",
                "        num_channels = 162\n",
                "\n",
                "    split_idx = int(len(valid_dates) * 0.8)\n",
                "    train_ds = GIBSSequenceDataset(valid_dates[:split_idx], config.PROCESSED_ROOT, target, config.HISTORY_DAYS, num_channels)\n",
                "    test_ds = GIBSSequenceDataset(valid_dates[split_idx:], config.PROCESSED_ROOT, target, config.HISTORY_DAYS, num_channels)\n",
                "    return train_ds, test_ds, num_channels"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "model_zoo_markdown",
            "metadata": {},
            "source": [
                "# Model Zoo\n",
                "Models defined as before."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "model_definitions",
            "metadata": {},
            "outputs": [],
            "source": [
                "# ... (Model classes code as defined previously, omitted here for brevity since they are unchanged, except we must ensure they accept variable input channels)\n",
                "# Note: I am rewriting them here to be self-contained in the file artifact.\n",
                "\n",
                "class DayEncoder(nn.Module):\n",
                "    def __init__(self, in_channels, hidden_dim=128):\n",
                "        super().__init__()\n",
                "        self.net = nn.Sequential(\n",
                "            nn.Conv2d(in_channels, 32, 3, 1, 1), nn.ReLU(), nn.MaxPool2d(2),\n",
                "            nn.Conv2d(32, 64, 3, 1, 1), nn.ReLU(), nn.MaxPool2d(2),\n",
                "            nn.Conv2d(64, 128, 3, 1, 1), nn.ReLU(), nn.AdaptiveAvgPool2d((1,1)),\n",
                "        )\n",
                "        self.proj = nn.Linear(128, hidden_dim)\n",
                "    def forward(self, x): return self.proj(self.net(x).view(x.size(0), -1))\n",
                "\n",
                "class GIBSForecaster(nn.Module):\n",
                "    def __init__(self, in_channels, history_days, hidden_dim=128, rnn_hidden=256):\n",
                "        super().__init__()\n",
                "        self.day_encoder = DayEncoder(in_channels, hidden_dim)\n",
                "        self.rnn = nn.GRU(hidden_dim, rnn_hidden, batch_first=True)\n",
                "        self.head = nn.Sequential(nn.Linear(rnn_hidden, 128), nn.ReLU(), nn.Linear(128, 1))\n",
                "    def forward(self, x):\n",
                "        b, t, c, h, w = x.shape\n",
                "        x = x.view(b * t, c, h, w)\n",
                "        out, _ = self.rnn(self.day_encoder(x).view(b, t, -1))\n",
                "        return self.head(out[:, -1, :]).squeeze(1)\n",
                "\n",
                "class CloudCoverNowcaster(nn.Module):\n",
                "    def __init__(self, in_channels=4, out_timesteps=6):\n",
                "        super().__init__()\n",
                "        self.enc1 = nn.Sequential(nn.Conv2d(in_channels, 64, 3, 1, 1), nn.BatchNorm2d(64), nn.ReLU())\n",
                "        self.enc2 = nn.Sequential(nn.Conv2d(64, 128, 3, 1, 1), nn.BatchNorm2d(128), nn.ReLU())\n",
                "        self.enc3 = nn.Sequential(nn.Conv2d(128, 256, 3, 1, 1), nn.BatchNorm2d(256), nn.ReLU())\n",
                "        self.pool = nn.MaxPool2d(2, 2)\n",
                "        self.bottleneck = nn.Sequential(nn.Conv2d(256, 512, 3, 1, 1), nn.BatchNorm2d(512), nn.ReLU())\n",
                "        self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
                "        self.dec3 = nn.Sequential(nn.Conv2d(512 + 256, 256, 3, 1, 1), nn.BatchNorm2d(256), nn.ReLU())\n",
                "        self.dec2 = nn.Sequential(nn.Conv2d(256 + 128, 128, 3, 1, 1), nn.BatchNorm2d(128), nn.ReLU())\n",
                "        self.dec1 = nn.Sequential(nn.Conv2d(128 + 64, 64, 3, 1, 1), nn.BatchNorm2d(64), nn.ReLU())\n",
                "        self.head = nn.Conv2d(64, out_timesteps, 1)\n",
                "    def forward(self, x):\n",
                "        e1 = self.pool(self.enc1(x))\n",
                "        e2 = self.pool(self.enc2(e1))\n",
                "        e3 = self.pool(self.enc3(e2))\n",
                "        b = self.bottleneck(e3)\n",
                "        d3 = self.dec3(torch.cat([self.up(b), e3], dim=1))\n",
                "        d2 = self.dec2(torch.cat([self.up(d3), e2], dim=1))\n",
                "        d1 = self.dec1(torch.cat([self.up(d2), self.enc1(x)], dim=1))\n",
                "        return torch.sigmoid(self.head(d1))\n",
                "\n",
                "class SIANet(nn.Module):\n",
                "    def __init__(self, in_channels=4, input_frames=4, output_frames=32):\n",
                "        super().__init__()\n",
                "        # Adjust to 3D\n",
                "        self.conv1 = nn.Conv3d(in_channels, 32, (3,3,3), padding=(1,1,1))\n",
                "        self.bn1 = nn.BatchNorm3d(32)\n",
                "        self.context = nn.Conv3d(32, 64, (3,5,5), padding=(1,2,2))\n",
                "        self.bn2 = nn.BatchNorm3d(64)\n",
                "        self.res_conv = nn.Conv3d(64, 64, 3, padding=1)\n",
                "        self.temporal_expand = nn.ConvTranspose3d(64, 32, (output_frames//input_frames, 1, 1), stride=(output_frames//input_frames, 1, 1))\n",
                "        self.out = nn.Conv3d(32, 1, 1)\n",
                "    def forward(self, x):\n",
                "        x = F.relu(self.bn1(self.conv1(x)))\n",
                "        x = F.relu(self.bn2(self.context(x)))\n",
                "        x = F.relu(x + self.res_conv(x))\n",
                "        return self.out(self.temporal_expand(x))\n",
                "\n",
                "class Pix2PixGenerator(nn.Module):\n",
                "    def __init__(self, in_channels=3, out_channels=2):\n",
                "        super().__init__()\n",
                "        self.down1 = nn.Conv2d(in_channels, 64, 4, 2, 1)\n",
                "        self.down2 = nn.Conv2d(64, 128, 4, 2, 1)\n",
                "        self.down3 = nn.Conv2d(128, 256, 4, 2, 1)\n",
                "        self.bottleneck = nn.Conv2d(256, 256, 4, 2, 1)\n",
                "        self.up1 = nn.ConvTranspose2d(256, 256, 4, 2, 1)\n",
                "        self.up2 = nn.ConvTranspose2d(512, 128, 4, 2, 1)\n",
                "        self.up3 = nn.ConvTranspose2d(256, 64, 4, 2, 1)\n",
                "        self.final = nn.ConvTranspose2d(128, out_channels, 4, 2, 1)\n",
                "    def forward(self, x):\n",
                "        d1 = F.leaky_relu(self.down1(x), 0.2)\n",
                "        d2 = F.leaky_relu(self.down2(d1), 0.2)\n",
                "        d3 = F.leaky_relu(self.down3(d2), 0.2)\n",
                "        b = F.relu(self.bottleneck(d3))\n",
                "        u1 = F.relu(self.up1(b))\n",
                "        u2 = F.relu(self.up2(torch.cat([u1, d3], dim=1)))\n",
                "        u3 = F.relu(self.up3(torch.cat([u2, d2], dim=1)))\n",
                "        return torch.tanh(self.final(torch.cat([u3, d1], dim=1)))\n",
                "\n",
                "class MicrowaveLSTNet(nn.Module):\n",
                "    def __init__(self, in_channels=10):\n",
                "        super().__init__()\n",
                "        self.features = nn.Sequential(\n",
                "            nn.Conv2d(in_channels, 32, 3, 1, 1), nn.ReLU(),\n",
                "            nn.Conv2d(32, 64, 3, 1, 1), nn.ReLU(),\n",
                "            nn.Conv2d(64, 32, 3, 1, 1), nn.ReLU(),\n",
                "        )\n",
                "        self.regressor = nn.Conv2d(32, 1, 1)\n",
                "    def forward(self, x): return self.regressor(self.features(x))\n",
                "\n",
                "class ConvectionCNN(nn.Module):\n",
                "    def __init__(self, in_channels=3):\n",
                "        super().__init__()\n",
                "        self.net = nn.Sequential(\n",
                "            nn.Conv2d(in_channels, 32, 3, 1), nn.ReLU(), nn.MaxPool2d(2),\n",
                "            nn.Conv2d(32, 64, 3, 1), nn.ReLU(), nn.MaxPool2d(2),\n",
                "            nn.Conv2d(64, 128, 3, 1), nn.ReLU(), nn.AdaptiveAvgPool2d((1,1)),\n",
                "            nn.Flatten(),\n",
                "            nn.Linear(128, 64), nn.ReLU(), nn.Linear(64, 1)\n",
                "        )\n",
                "    def forward(self, x): return torch.sigmoid(self.net(x))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "verbose_trainer",
            "metadata": {},
            "outputs": [],
            "source": [
                "class UnifiedTrainer:\n",
                "    def __init__(self, model, device, optimizer, criterion, task_type=\"regression\"):\n",
                "        self.model = model\n",
                "        self.device = device\n",
                "        self.optimizer = optimizer\n",
                "        self.criterion = criterion\n",
                "        self.task_type = task_type\n",
                "\n",
                "    def train_epoch(self, loader, desc=\"Task\"):\n",
                "        self.model.train()\n",
                "        total_loss = 0\n",
                "        start_time = time.time()\n",
                "        \n",
                "        print(f\"[{desc}] Starting Epoch on {self.device}. Batch Count: {len(loader)}\")\n",
                "        \n",
                "        for i, (x, y) in enumerate(loader):\n",
                "            # === CRITICAL: Ensure tensors are on device ===\n",
                "            x = x.to(self.device, non_blocking=True)\n",
                "            y = y.to(self.device, non_blocking=True)\n",
                "            \n",
                "            if i == 0:\n",
                "                print(f\"VERBOSE DEBUG: Batch 0 | Input Shape: {x.shape} | Target Shape: {y.shape} | Device: {x.device}\")\n",
                "            \n",
                "            self.optimizer.zero_grad()\n",
                "            pred = self.model(x)\n",
                "            loss = self.criterion(pred, y)\n",
                "            loss.backward()\n",
                "            self.optimizer.step()\n",
                "            \n",
                "            total_loss += loss.item()\n",
                "            \n",
                "            # Log every 10% progress\n",
                "            if i > 0 and i % max(1, len(loader)//10) == 0:\n",
                "                print(f\"[{desc}] Step {i}/{len(loader)} | Current Loss: {loss.item():.4f}\")\n",
                "            \n",
                "        avg_loss = total_loss / len(loader)\n",
                "        duration = time.time() - start_time\n",
                "        print(f\"[{desc}] Epoch Complete in {duration:.2f}s | Avg Loss: {avg_loss:.4f}\")\n",
                "        return avg_loss"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "run_training_all",
            "metadata": {},
            "outputs": [],
            "source": [
                "# === MAIN EXECUTION ===\n",
                "\n",
                "files, dates = discover_files(config)\n",
                "print(f\"Found {len(files)} total tensor files in {config.PROCESSED_ROOT}\")\n",
                "\n",
                "if len(files) > 0:\n",
                "    # 1. TMAX Training (Still runs once)\n",
                "    print(\"\\n=== TMAX FORECAST ===\")\n",
                "    train_ds, test_ds, num_channels = prepare_tmax_data(config)\n",
                "    if train_ds:\n",
                "        loader_kwargs = {'num_workers': 2, 'pin_memory': True} if DEVICE.type == 'cuda' else {}\n",
                "        dl = DataLoader(train_ds, batch_size=config.BATCH_SIZE, shuffle=True, **loader_kwargs)\n",
                "        model = GIBSForecaster(in_channels=num_channels, history_days=config.HISTORY_DAYS).to(DEVICE)\n",
                "        opt = torch.optim.Adam(model.parameters(), lr=config.LEARNING_RATE)\n",
                "        trainer = UnifiedTrainer(model, DEVICE, opt, nn.L1Loss())\n",
                "        trainer.train_epoch(dl, desc=\"TMAX\")\n",
                "\n",
                "    # Function to run both variants\n",
                "    def run_variants(name, dataset_cls, model_cls, in_ch_smart, in_ch_all, **ds_kwargs):\n",
                "        print(f\"\\n=== {name} COMPARISON ===\")\n",
                "        loader_kwargs = {'num_workers': 2, 'pin_memory': True} if DEVICE.type == 'cuda' else {}\n",
                "        \n",
                "        # 1. Smart Selection\n",
                "        print(f\"--- {name} (Smart Selection: {in_ch_smart} ch) ---\")\n",
                "        ds_smart = dataset_cls(files if 'files' not in ds_kwargs else ds_kwargs['files'], use_all_channels=False)\n",
                "        dl_smart = DataLoader(ds_smart, batch_size=config.BATCH_SIZE, shuffle=True, **loader_kwargs)\n",
                "        model_smart = model_cls(in_channels=in_ch_smart).to(DEVICE)\n",
                "        opt = torch.optim.Adam(model_smart.parameters(), lr=config.LEARNING_RATE)\n",
                "        crit = nn.BCEWithLogitsLoss() if name == \"Convection\" else nn.MSELoss()\n",
                "        trainer = UnifiedTrainer(model_smart, DEVICE, opt, crit)\n",
                "        trainer.train_epoch(dl_smart, desc=f\"{name}-Smart\")\n",
                "        \n",
                "        # 2. All Channels\n",
                "        print(f\"--- {name} (All Channels: {in_ch_all} ch) ---\")\n",
                "        ds_all = dataset_cls(files if 'files' not in ds_kwargs else ds_kwargs['files'], use_all_channels=True)\n",
                "        dl_all = DataLoader(ds_all, batch_size=config.BATCH_SIZE, shuffle=True, **loader_kwargs)\n",
                "        model_all = model_cls(in_channels=in_ch_all).to(DEVICE)\n",
                "        opt = torch.optim.Adam(model_all.parameters(), lr=config.LEARNING_RATE)\n",
                "        trainer = UnifiedTrainer(model_all, DEVICE, opt, crit)\n",
                "        trainer.train_epoch(dl_all, desc=f\"{name}-All162\")\n",
                "        \n",
                "    # Run all models\n",
                "    \n",
                "    # Cloud Cover: Smart=4, All=162\n",
                "    run_variants(\"CloudCover\", CloudCoverDataset, CloudCoverNowcaster, 4, 162)\n",
                "\n",
                "    # SIANet: Smart=4, All=162 (Pass specialized dates)\n",
                "    # Note: SIANetDataset constructor args differ slightly, so we adapt manual call\n",
                "    print(\"\\n=== SIANet COMPARISON ===\")\n",
                "    sianet_ds_smart = SIANetDataset(dates, config.PROCESSED_ROOT, use_all_channels=False)\n",
                "    if len(sianet_ds_smart) > 0:\n",
                "        dl_s = DataLoader(sianet_ds_smart, batch_size=8, shuffle=True)\n",
                "        m_s = SIANet(in_channels=4).to(DEVICE)\n",
                "        t_s = UnifiedTrainer(m_s, DEVICE, torch.optim.Adam(m_s.parameters(), lr=config.LEARNING_RATE), nn.MSELoss())\n",
                "        t_s.train_epoch(dl_s, desc=\"SIANet-Smart\")\n",
                "        \n",
                "        sianet_ds_all = SIANetDataset(dates, config.PROCESSED_ROOT, use_all_channels=True)\n",
                "        dl_a = DataLoader(sianet_ds_all, batch_size=8, shuffle=True)\n",
                "        m_a = SIANet(in_channels=162).to(DEVICE)\n",
                "        t_a = UnifiedTrainer(m_a, DEVICE, torch.optim.Adam(m_a.parameters(), lr=config.LEARNING_RATE), nn.MSELoss())\n",
                "        t_a.train_epoch(dl_a, desc=\"SIANet-All162\")\n",
                "\n",
                "    # Pix2Pix: Smart=3, All=162\n",
                "    run_variants(\"Pix2Pix\", Pix2PixDataset, Pix2PixGenerator, 3, 162)\n",
                "    \n",
                "    # Microwave: Smart=10, All=162\n",
                "    run_variants(\"Microwave\", MicrowaveDataset, MicrowaveLSTNet, 10, 162)\n",
                "    \n",
                "    # Convection: Smart=3, All=162\n",
                "    run_variants(\"Convection\", ConvectionDataset, ConvectionCNN, 3, 162)\n",
                "\n",
                "else:\n",
                "    print(\"No .pt files found.\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}